{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ! pip install huggingface_hub\n",
    "# ! pip install torch\n",
    "# ! pip install transformers==4.40.2\n",
    "# ! pip install datasets\n",
    "# ! pip install evaluate\n",
    "# ! pip install sacrebleu\n",
    "# ! pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! huggingface-cli login --token $HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"=datas/new_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df) - len(raw_df) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = raw_df.copy()\n",
    "val_df = raw_df[6144:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train_df.English[0]} ---> {train_df.Twi[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS_TO_REMOVE_REGEX = '[!\"&\\(\\),-./:;=?+.\\n\\[\\]]'\n",
    "SRC_LANG = \"English\"\n",
    "TRG_LANG = \"Twi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data (lowercase and punctuation)\n",
    "import re\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub(CHARS_TO_REMOVE_REGEX, \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_text(batch):\n",
    "    # process source text\n",
    "    batch[SRC_LANG] = remove_special_characters(batch[SRC_LANG])\n",
    "    # process target text\n",
    "    batch[TRG_LANG] = remove_special_characters(batch[TRG_LANG])\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][32]['English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][32]['Twi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM , NllbTokenizerFast\n",
    "\n",
    "tokenizer = NllbTokenizerFast.from_pretrained(\n",
    "    \"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\", tgt_lang=\"twi_Latn\"\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[SRC_LANG]\n",
    "    targets = examples[TRG_LANG]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
    "    )\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function,\n",
    "                                 remove_columns=dataset[\"train\"].column_names,\n",
    "                                 batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 3):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load both ROUGE and BLEU metrics\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # Check if preds is a tuple and extract the logits if it is\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    # Ensure preds are integers and within valid range\n",
    "    preds = np.array(preds, dtype=np.int64)\n",
    "    if np.any(preds < 0) or np.any(preds >= tokenizer.vocab_size):\n",
    "        print(\"Warning: Preds contain out-of-range values\")\n",
    "        preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
    "\n",
    "    # Decode the predictions using the tokenizer\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    # Compute the ROUGE scores\n",
    "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    rouge_scores = {\n",
    "        \"rouge1\": rouge_result[\"rouge1\"],\n",
    "    }\n",
    "\n",
    "    # Compute the BLEU score\n",
    "    bleu_result = bleu_metric.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])\n",
    "    bleu_score = {\"bleu\": bleu_result[\"score\"]}\n",
    "\n",
    "    # Combine both metrics into a single dictionary\n",
    "    result = {**rouge_scores, **bleu_score}\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"saved_model\",\n",
    "    report_to='none',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=25,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers.optimization import Adafactor, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "tokenizer.save_pretrained(\"saved_model\")\n",
    "model.save_pretrained(\"saved_model\")\n",
    "trainer.save_model(\"saved_model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
