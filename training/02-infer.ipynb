{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch\n",
    "# ! pip install transformers==4.40.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS_TO_REMOVE_REGEX = '[!\"&\\(\\),-./:;=?+.\\n\\[\\]]'\n",
    "SRC_LANG = \"Twi\"\n",
    "TRG_LANG = \"English\"\n",
    "DIR = 'saved_model'\n",
    "MODEL_KWARGS = {\n",
    "    \"do_sample\":True,\n",
    "    \"max_new_tokens\": 40,\n",
    "    \"top_k\":2,\n",
    "    \"top_p\":0.1,\n",
    "    \"temperature\":0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DIR)\n",
    "loaded_model = AutoModelForSeq2SeqLM.from_pretrained(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"Pregnancy is one thing that's not easy to deal with.\"\n",
    "inputs = loaded_tokenizer(example, return_tensors=\"pt\").input_ids\n",
    "outputs = loaded_model.generate(inputs, **MODEL_KWARGS)\n",
    "translation = loaded_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "translation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
